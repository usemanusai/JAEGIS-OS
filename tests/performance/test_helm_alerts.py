#!/usr/bin/env python3
"""
Test script for H.E.L.M. Alerting and Notification System
Task 1.4.2: Alerting and Notification System

Tests H.E.L.M.-specific alerting features:
- Failed discovery alerts
- Storage quota warnings
- Performance degradation alerts
- API rate limiting alerts
- Validation quality alerts
"""

import sys
import time
from core.helm.monitoring.helm_alerts import (
    HELMAlertManager,
    HELMAlertConfig,
    create_helm_alert_manager
)
from core.helm.monitoring.alerting import AlertLevel
from common.utils import metrics

def test_helm_alerting_system():
    """Test the H.E.L.M.-specific alerting system"""
    print("üîß Testing H.E.L.M. Alerting and Notification System")
    print("=" * 50)
    
    try:
        # Test 1: H.E.L.M. Alert Manager Creation
        print("üö® Test 1: H.E.L.M. Alert Manager Creation")
        
        # Create custom configuration
        config = HELMAlertConfig(
            discovery_failure_rate_warning=0.15,  # 15% failure rate
            discovery_failure_rate_critical=0.40,  # 40% failure rate
            search_latency_warning=8.0,  # 8 seconds
            storage_usage_warning=75.0,  # 75% of quota
            enable_email_notifications=True,
            enable_webhook_notifications=True
        )
        
        alert_manager = HELMAlertManager(config=config)
        print(f"   Alert manager created with custom config")
        print(f"   Discovery failure warning threshold: {config.discovery_failure_rate_warning:.1%}")
        print(f"   Search latency warning threshold: {config.search_latency_warning}s")
        
        print("‚úÖ H.E.L.M. alert manager creation working")
        
        # Test 2: Alert Rule Registration
        print("\nüìã Test 2: H.E.L.M. Alert Rule Registration")
        
        # Check that H.E.L.M.-specific rules were registered
        alert_summary = alert_manager.get_alert_summary()
        print(f"   Total alert rules: {alert_summary.get('alert_rules', 0)}")
        print(f"   H.E.L.M.-specific rules: {alert_summary.get('helm_specific_rules', 0)}")
        
        print("‚úÖ H.E.L.M. alert rule registration working")
        
        # Test 3: Discovery Failure Alerts
        print("\nüîç Test 3: Discovery Failure Alerts")
        
        # Simulate discovery failures
        collector = get_global_collector()
        
        # Simulate some successful and failed discoveries
        for i in range(10):
            collector.increment_counter("helm_discovery_calls")
            if i < 3:  # 30% failure rate
                collector.increment_counter("helm_discovery_errors")
        
        # Create specific discovery failure alert
        failure_alert_id = alert_manager.create_discovery_failure_alert(
            source="tavily_api",
            error_message="API rate limit exceeded",
            metadata={"api_key": "key_123", "retry_after": 60}
        )
        
        print(f"   Discovery failure alert created: {failure_alert_id}")
        
        # Evaluate metrics to trigger automatic alerts
        triggered_alerts = alert_manager.evaluate_helm_metrics()
        print(f"   Automatic alerts triggered: {len(triggered_alerts)}")
        
        print("‚úÖ Discovery failure alerts working")
        
        # Test 4: Performance Degradation Alerts
        print("\n‚ö° Test 4: Performance Degradation Alerts")
        
        # Simulate slow search operations
        for i in range(5):
            collector.record_metric("helm_search_duration", 12.0 + i)  # Above warning threshold
        
        # Create specific performance alert
        perf_alert_id = alert_manager.create_performance_degradation_alert(
            component="search",
            metric="average_latency",
            value=12.5,
            threshold=8.0
        )
        
        print(f"   Performance degradation alert created: {perf_alert_id}")
        
        # Evaluate performance metrics
        perf_triggered = alert_manager.evaluate_helm_metrics()
        print(f"   Performance alerts triggered: {len(perf_triggered)}")
        
        print("‚úÖ Performance degradation alerts working")
        
        # Test 5: Storage Quota Alerts
        print("\nüíæ Test 5: Storage Quota Alerts")
        
        # Create storage quota alert
        storage_alert_id = alert_manager.create_storage_quota_alert(
            usage_percent=82.5,
            quota_gb=100.0
        )
        
        print(f"   Storage quota alert created: {storage_alert_id}")
        
        # Test critical storage alert
        critical_storage_alert_id = alert_manager.create_storage_quota_alert(
            usage_percent=96.8,
            quota_gb=100.0
        )
        
        print(f"   Critical storage alert created: {critical_storage_alert_id}")
        
        print("‚úÖ Storage quota alerts working")
        
        # Test 6: Validation Quality Alerts
        print("\nüéØ Test 6: Validation Quality Alerts")
        
        # Simulate low validation confidence
        for i in range(5):
            collector.record_metric("helm_validation_confidence", 0.45 + i * 0.02)  # Below warning threshold
        
        # Simulate low deduplication efficiency
        for i in range(3):
            collector.record_metric("helm_deduplication_rate", 0.05 + i * 0.01)  # Below warning threshold
        
        # Evaluate quality metrics
        quality_triggered = alert_manager.evaluate_helm_metrics()
        print(f"   Quality alerts triggered: {len(quality_triggered)}")
        
        print("‚úÖ Validation quality alerts working")
        
        # Test 7: Alert Summary and Statistics
        print("\nüìä Test 7: Alert Summary and Statistics")
        
        final_summary = alert_manager.get_alert_summary()
        print(f"   Total alerts: {final_summary['total_alerts']}")
        print(f"   Active alerts: {final_summary['active_alerts']}")
        print(f"   Discovery alerts: {final_summary['discovery_alerts']}")
        print(f"   Performance alerts: {final_summary['performance_alerts']}")
        print(f"   Storage alerts: {final_summary['storage_alerts']}")
        print(f"   Critical alerts: {final_summary['alerts_by_level']['critical']}")
        print(f"   Warning alerts: {final_summary['alerts_by_level']['warning']}")
        
        print("‚úÖ Alert summary and statistics working")
        
        # Test 8: Notification Channels
        print("\nüì¢ Test 8: Notification Channels")
        
        # Test factory function
        factory_manager = create_helm_alert_manager()
        print("   Factory function working")
        
        # Check notification channels
        channels = factory_manager.alerting_system._notification_channels
        print(f"   Notification channels registered: {len(channels)}")
        for channel_name, channel in channels.items():
            print(f"     {channel_name}: {channel.type} ({'enabled' if channel.enabled else 'disabled'})")
        
        print("‚úÖ Notification channels working")
        
        # Test 9: Alert Configuration
        print("\n‚öôÔ∏è Test 9: Alert Configuration")
        
        # Test different configuration options
        strict_config = HELMAlertConfig(
            discovery_failure_rate_warning=0.05,  # Very strict
            search_latency_warning=3.0,  # Very strict
            storage_usage_warning=60.0,  # Very strict
            enable_slack_notifications=True
        )
        
        strict_manager = HELMAlertManager(config=strict_config)
        print("   Strict configuration manager created")
        
        # Test with relaxed configuration
        relaxed_config = HELMAlertConfig(
            discovery_failure_rate_warning=0.50,  # Very relaxed
            search_latency_warning=30.0,  # Very relaxed
            storage_usage_warning=95.0,  # Very relaxed
        )
        
        relaxed_manager = HELMAlertManager(config=relaxed_config)
        print("   Relaxed configuration manager created")
        
        print("‚úÖ Alert configuration working")
        
        print("\nüéâ All tests passed! H.E.L.M. Alerting System is ready.")
        print("\nüìã Implementation Summary:")
        print("   ‚úÖ Discovery failure alerts with configurable thresholds")
        print("   ‚úÖ Performance degradation monitoring and alerts")
        print("   ‚úÖ Storage quota warnings with critical escalation")
        print("   ‚úÖ API rate limiting alerts")
        print("   ‚úÖ Validation quality monitoring")
        print("   ‚úÖ Multi-channel notification system")
        print("   ‚úÖ Configurable alert thresholds and cooldowns")
        print("   ‚úÖ H.E.L.M.-specific alert rules and metrics")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_alert_scenarios():
    """Test various alert scenarios"""
    print("\nüî¨ Testing Alert Scenarios")
    print("=" * 50)
    
    try:
        alert_manager = create_helm_alert_manager()
        collector = get_global_collector()
        
        # Scenario 1: High Discovery Failure Rate
        print("üìä Scenario 1: High Discovery Failure Rate")
        
        # Simulate high failure rate
        for i in range(20):
            collector.increment_counter("helm_discovery_calls")
            if i < 12:  # 60% failure rate
                collector.increment_counter("helm_discovery_errors")
        
        triggered = alert_manager.evaluate_helm_metrics()
        print(f"   Alerts triggered for high failure rate: {len(triggered)}")
        
        # Scenario 2: Performance Degradation
        print("\n‚ö° Scenario 2: Performance Degradation")
        
        # Simulate degraded performance
        for i in range(10):
            collector.record_metric("helm_search_duration", 15.0 + i)  # Very slow
            collector.record_metric("helm_validation_duration", 25.0 + i)  # Very slow
        
        triggered = alert_manager.evaluate_helm_metrics()
        print(f"   Alerts triggered for performance issues: {len(triggered)}")
        
        # Scenario 3: Quality Issues
        print("\nüéØ Scenario 3: Quality Issues")
        
        # Simulate quality problems
        for i in range(8):
            collector.record_metric("helm_validation_confidence", 0.40 + i * 0.01)  # Low confidence
            collector.record_metric("helm_deduplication_rate", 0.02 + i * 0.005)  # Poor deduplication
        
        triggered = alert_manager.evaluate_helm_metrics()
        print(f"   Alerts triggered for quality issues: {len(triggered)}")
        
        print("‚úÖ Alert scenarios testing completed")
        return True
        
    except Exception as e:
        print(f"‚ùå Scenario test failed: {e}")
        return False

if __name__ == "__main__":
    print("üöÄ H.E.L.M. Alerting and Notification Test Suite")
    print("=" * 60)
    
    # Run main tests
    success1 = test_helm_alerting_system()
    
    # Run scenario tests
    success2 = test_alert_scenarios()
    
    overall_success = success1 and success2
    
    if overall_success:
        print("\n‚úÖ Task 1.4.2: Alerting and Notification System - COMPLETED")
        print("   üîç Discovery failure alerts: IMPLEMENTED")
        print("   üíæ Storage quota warnings: IMPLEMENTED") 
        print("   ‚ö° Performance degradation alerts: IMPLEMENTED")
        print("   üéØ Quality monitoring alerts: IMPLEMENTED")
        print("   üì¢ Multi-channel notifications: IMPLEMENTED")
    else:
        print("\n‚ùå Task 1.4.2: Alerting and Notification System - FAILED")
    
    sys.exit(0 if overall_success else 1)
